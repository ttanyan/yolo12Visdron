import cv2
import torch
import numpy as np
import subprocess
from ultralytics import YOLO
from multiprocessing import Process, Queue, Manager
import time

# --- 1. æ€§èƒ½å‚æ•°é…ç½® ---
BATCH_SIZE = 4  # æ¯æ¬¡æ¨ç† 4 å¸§ï¼Œå……åˆ†åˆ©ç”¨ 3070Ti ç®—åŠ›
IMG_SIZE = 960  # è®­ç»ƒæ—¶çš„åˆ†è¾¨ç‡
VIDEO_PATH = "DJI_20251231200946_0001_V.mp4"
OUTPUT_PATH = "Turbo_NVENC_Output.mp4"


def frame_reader(video_path, task_queue):
    """ã€è¿›ç¨‹ Aã€‘è¯»å–è§†é¢‘ï¼šå…¨åŠ›è¯»å–åŸå§‹å¸§å¹¶å‹å…¥é˜Ÿåˆ—"""
    cap = cv2.VideoCapture(video_path)
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret: break
        # å¦‚æœé˜Ÿåˆ—å¤ªæ»¡åˆ™ç¨ç­‰ï¼Œé˜²æ­¢æ’‘çˆ†å†…å­˜
        while task_queue.qsize() > 100: time.sleep(0.01)
        task_queue.put(frame)
    cap.release()
    task_queue.put(None)  # ç»“æŸæ ‡å¿—


def gpu_inference(task_queue, result_queue, model_path):
    """ã€è¿›ç¨‹ Bã€‘GPU æ¨ç†ï¼šè´Ÿè´£æœ€æ ¸å¿ƒçš„ AI è®¡ç®—"""
    device = torch.device("cuda:0")
    model = YOLO(model_path).to(device)

    # å¯ç”¨ FP16 åŠç²¾åº¦å’Œæ€§èƒ½ä¼˜åŒ–
    model.model.half()

    batch = []
    while True:
        frame = task_queue.get()
        if frame is None: break

        batch.append(frame)

        # å½“å‡‘å¤Ÿä¸€ä¸ª Batch æˆ–è€…æ”¶åˆ°ç»“æŸä¿¡å·æ—¶è¿›è¡Œæ¨ç†
        if len(batch) == BATCH_SIZE:
            # æ‰¹é‡æ¨ç†æå‡ GPU åˆ©ç”¨ç‡
            results = model.predict(batch, imgsz=IMG_SIZE, device=device, half=True, verbose=False)
            for res in results:
                result_queue.put(res)
            batch = []

    result_queue.put(None)


def video_writer_nvenc(result_queue, width, height, fps):
    """ã€è¿›ç¨‹ Cã€‘ç¡¬ç¼–ç å†™å…¥ï¼šåˆ©ç”¨ 3070Ti çš„ NVENC èŠ¯ç‰‡ï¼Œä¸å  CPU"""
    # ä½¿ç”¨ FFmpeg è°ƒç”¨ NVENC ç¡¬ä»¶åŠ é€Ÿç¡¬ç¼–ç 
    command = [
        'ffmpeg',
        '-y', '-f', 'rawvideo', '-vcodec', 'rawvideo',
        '-s', f'{width}x{height}', '-pix_fmt', 'bgr24', '-r', str(fps),
        '-i', '-',  # ä»ç®¡é“è¾“å…¥
        '-c:v', 'h264_nvenc',  # å…³é”®ï¼šè°ƒç”¨ NVIDIA ç¡¬ä»¶ç¼–ç å™¨
        '-preset', 'fast', '-b:v', '20M',  # é«˜ç ç‡ä¿è¯ 4K ç”»è´¨
        OUTPUT_PATH
    ]

    # å¼€å¯å­è¿›ç¨‹
    pipe = subprocess.Popen(command, stdin=subprocess.PIPE)

    processed_count = 0
    start_time = time.time()

    while True:
        result = result_queue.get()
        if result is None: break

        # æ¸²æŸ“ (plot åœ¨ CPU ä¸Šè¿è¡Œï¼Œi9 çš„å¤šæ ¸ä¼˜åŠ¿åœ¨è¿™é‡Œä½“ç°)
        annotated_frame = result.plot(line_width=2)

        # å†™å…¥ FFmpeg ç®¡é“
        pipe.stdin.write(annotated_frame.tobytes())
        processed_count += 1

        if processed_count % 50 == 0:
            avg_fps = processed_count / (time.time() - start_time)
            vram = torch.cuda.memory_reserved() / 1e9
            print(f"\rğŸ”¥ ç¡¬ä»¶å…¨å¼€æ¨¡å¼: {processed_count} å¸§ | é€Ÿåº¦: {avg_fps:.1f} FPS | æ˜¾å­˜: {vram:.2f}GB", end="")

    pipe.stdin.close()
    pipe.wait()


if __name__ == "__main__":
    # è·å–è§†é¢‘å‚æ•°
    cap = cv2.VideoCapture(VIDEO_PATH)
    W = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    H = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    FPS = cap.get(cv2.CAP_PROP_FPS)
    cap.release()

    # è·¨è¿›ç¨‹é€šä¿¡é˜Ÿåˆ—
    task_q = Queue(maxsize=128)
    result_q = Queue(maxsize=128)

    MODEL_WT = "DJI_VisDrone_12n/yolo12n_3070Ti_1280/weights/960best.pt"

    # å¯åŠ¨å¤šè¿›ç¨‹æ¶æ„
    p_read = Process(target=frame_reader, args=(VIDEO_PATH, task_q))
    p_infer = Process(target=gpu_inference, args=(task_q, result_q, MODEL_WT))
    p_write = Process(target=video_writer_nvenc, args=(result_q, W, H, FPS))

    print(f"--- å¯åŠ¨ i9 + 3070Ti NVENC å¹¶å‘å¼•æ“ ---")
    p_read.start()
    p_infer.start()
    p_write.start()

    p_read.join()
    p_infer.join()
    p_write.join()
    print(f"\n[{time.strftime('%H:%M:%S')}] æ‰€æœ‰æ ¸å¿ƒä»»åŠ¡å·²å®Œæˆï¼")