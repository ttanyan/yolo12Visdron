import cv2
import torch
import time
import sys
import os
from threading import Thread
from queue import Queue
from ultralytics import YOLO
from datetime import datetime

# --- 1. é…ç½®å‚æ•° ---
VIDEO_PATH = "DJI_20251231222628_0001_V.mp4"
MODEL_PATH = "DJI_VisDrone_12n/yolo12n_3070Ti_9602/weights/best.pt"
OUTPUT_PATH = "Deep_Optimized_DJI_960test1.mp4"
BATCH_SIZE = 4  # 3070Ti 8G æ˜¾å­˜å¯ä»¥å°è¯• 4-8ï¼Œè¶Šå¤§æ˜¾å­˜å ç”¨è¶Šé«˜ï¼Œé€Ÿåº¦è¶Šå¿«


class DJIProcessor:
    def __init__(self, video_path, model_path):
        self.device = torch.device("cuda:0")
        self.model = YOLO("DJI_VisDrone_12s/yolo12s_3070Ti_960/weights/best.pt").to(self.device)

        # è§†é¢‘å…ƒæ•°æ®
        cap = cv2.VideoCapture(video_path)
        self.width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        self.height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        self.fps = cap.get(cv2.CAP_PROP_FPS)
        self.total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        cap.release()

        # é˜Ÿåˆ—å®šä¹‰ (é™åˆ¶å¤§å°é˜²æ­¢å†…å­˜æº¢å‡º)
        self.raw_queue = Queue(maxsize=128)
        self.result_queue = Queue(maxsize=128)
        self.stopped = False

    def reader(self):
        """çº¿ç¨‹1: è´Ÿè´£é«˜é€Ÿè¯»å–è§†é¢‘å¸§"""
        cap = cv2.VideoCapture(VIDEO_PATH)
        while not self.stopped:
            if not self.raw_queue.full():
                ret, frame = cap.read()
                if not ret:
                    self.stopped = True
                    break
                self.raw_queue.put(frame)
            else:
                time.sleep(0.001)
        cap.release()

    def inference(self):
        """çº¿ç¨‹2: è´Ÿè´£ GPU æ¨ç†"""
        # ä½¿ç”¨ç”Ÿæˆå™¨æ¨¡å¼é…åˆ stream=True
        results_gen = self.model.predict(
            source=VIDEO_PATH,
            imgsz=960,
            device=self.device,
            stream=True,
            half=True,  # å¼ºçƒˆå»ºè®®å¼€å¯ï¼š3070Ti ä¸‹ä¸æŸå¤±ç²¾åº¦ä¸”æ˜¾è‘—é™æ¸©ã€æé€Ÿ
            conf=0.15,  # æƒè¡¡å€¼ï¼š0.15 å¯èƒ½ä¼šå¯¼è‡´ç”»é¢èƒŒæ™¯â€œé—ªçƒâ€è™šè­¦ï¼Œ0.2 æ›´ç¨³
            iou=0.7,  # ä¿æŒ 0.7ï¼šå¯†é›†åœºæ™¯å¿…é¡»æ”¾å®½ IOUï¼Œé˜²æ­¢å¹¶æ’çš„äººè¢«å‰”é™¤
            agnostic_nms=False,  # å…³é”®ï¼šè®¾ä¸º Falseã€‚å¦‚æœè¡Œäººå’Œè‡ªè¡Œè½¦é‡å ï¼Œä¸¤è€…éƒ½ä¼šä¿ç•™
            max_det=4000,  # å¿…é¡»è°ƒå¤§ï¼šVisDrone 4K åœºæ™¯ä¸€å¸§å¯èƒ½æœ‰å‡ ç™¾ä¸ªç›®æ ‡ï¼Œé»˜è®¤ 300 å¯èƒ½ä¸å¤Ÿ
            augment=False,  # å®æ—¶æ¨ç†å»ºè®® Falseï¼Œå¦‚æœè¿½æ±‚æè‡´ç²¾åº¦ä¸”ä¸è®¡æˆæœ¬å¯è®¾ä¸º True
            classes=[0, 1, 2],  # å¦‚æœä½ åªå…³å¿ƒè½¦å’Œäººï¼Œå¯ä»¥æŒ‡å®šç±»åˆ«ç´¢å¼•ï¼Œå¦‚ [0, 1, 2]
            verbose=False
        )

        for result in results_gen:
            if self.stopped: break
            # å°† GPU ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
            self.result_queue.put(result)
        self.stopped = True

    def writer(self):
        """çº¿ç¨‹3: è´Ÿè´£ç»˜åˆ¶ UI å¹¶å†™å…¥ç¡¬ç›˜"""
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(OUTPUT_PATH, fourcc, self.fps, (self.width, self.height))

        processed_count = 0
        start_time = time.time()

        while not (self.stopped and self.result_queue.empty()):
            if not self.result_queue.empty():
                result = self.result_queue.get()

                # ç»˜åˆ¶ç›®æ ‡æ¡†
                annotated_frame = result.plot(line_width=2)

                # æå–ç»Ÿè®¡æ•°æ®
                if result.boxes is not None:
                    counts = result.boxes.cls.int().unique(return_counts=True)
                    # ç®€å•ç»˜åˆ¶æ€»æ•°ï¼Œå‡å°‘ CPU ç»˜å›¾è´Ÿæ‹…
                    total = len(result.boxes)
                    cv2.putText(annotated_frame, f"Detections: {total}", (50, 100),
                                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)

                out.write(annotated_frame)
                processed_count += 1

                # æ€§èƒ½å®æ—¶çœ‹æ¿
                if processed_count % 30 == 0:
                    elapsed = time.time() - start_time
                    fps = processed_count / elapsed
                    vram = torch.cuda.memory_reserved() / 1e9
                    sys.stdout.write(f"\rğŸ”¥ å¼‚æ­¥å¼•æ“å…¨åŠ›è¿è¡Œ: {processed_count}/{self.total_frames} | "
                                     f"é€Ÿåº¦: {fps:.1f} FPS | æ˜¾å­˜: {vram:.2f}GB")
                    sys.stdout.flush()
            else:
                time.sleep(0.001)

        out.release()

    def run(self):
        print(f"[{datetime.now().strftime('%H:%M:%S')}] å¼€å¯ç”Ÿäº§è€…-æ¶ˆè´¹è€…é«˜æ€§èƒ½æ¨¡å¼...")

        # å¯åŠ¨ä¸‰ä¸ªç‹¬ç«‹çº¿ç¨‹
        t_read = Thread(target=self.reader)
        t_infer = Thread(target=self.inference)
        t_write = Thread(target=self.writer)

        t_read.start()
        t_infer.start()
        t_write.start()

        t_read.join()
        t_infer.join()
        t_write.join()
        print(f"\nâœ… å¤„ç†å®Œæˆï¼è¾“å‡ºè§†é¢‘: {OUTPUT_PATH}")


if __name__ == "__main__":
    processor = DJIProcessor(VIDEO_PATH, MODEL_PATH)
    processor.run()